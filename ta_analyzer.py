# -*- coding: utf-8 -*-
import os, time, logging, json
from datetime import datetime
from pytz import timezone
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import numpy as np
import yfinance as yf
import ta_helpers 

logger = logging.getLogger(__name__)
TAIPEI_TZ = timezone('Asia/Taipei')

# === 1. æŠ€è¡“æŒ‡æ¨™è¨ˆç®— ===

def stoch(high, low, close, k_period=9):
    h = np.array(high).flatten().astype(float)
    l = np.array(low).flatten().astype(float)
    c = np.array(close).flatten().astype(float)
    n = len(c)
    k = np.full(n, np.nan)
    for i in range(k_period - 1, n):
        ll = np.min(l[i - k_period + 1 : i + 1])
        hh = np.max(h[i - k_period + 1 : i + 1])
        if hh - ll != 0:
            k[i] = 100 * (c[i] - ll) / (hh - ll)
    return k

def sma(arr, period):
    s = pd.Series(np.array(arr).flatten())
    if len(s) < period: return np.full(len(s), np.nan)
    return s.rolling(period).mean().values

def macd(close, fast=12, slow=26, signal=9):
    c = pd.Series(np.array(close).flatten().astype(float))
    ema_fast = c.ewm(span=fast, adjust=False).mean()
    ema_slow = c.ewm(span=slow, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    signal_line = macd_line.ewm(span=signal, adjust=False).mean()
    hist = macd_line - signal_line
    return macd_line.values, signal_line.values, hist.values

# === 2. æ¬„ä½æ˜ å°„ ===
COLUMN_MAP = {
    'latest_close': 'D',
    'KD_Signal': 'J',     'KD_ALERT_DATE': 'L',
    'MACD_Signal': 'M',   'MACD_ALERT_DATE': 'O',
    'MA5_MA10_Sig': 'P',  'MA5_MA10_ALERT_DATE': 'R',
    'MA5_MA20_Sig': 'S',  'MA5_MA20_ALERT_DATE': 'U',
    'MA10_MA20_Sig': 'V', 'MA10_MA20_ALERT_DATE': 'X',
    'Alert_Detail': 'AE', 'alert_time': 'AF', 
    'MA5_SLOPE': 'AB',    'MA10_SLOPE': 'AC',    'MA20_SLOPE': 'AD',
    'MA_TANGLE': 'Z',     'SLOPE_DESC': 'AA',    'BIAS_Val': 'Y'
}

def excel_col_to_index(col_letter):
    index = 0
    for i, letter in enumerate(reversed(col_letter.upper())):
        index += (ord(letter) - ord('A') + 1) * (26 ** i)
    return index - 1

# --- 3. ä¸‹è¼‰å™¨ ---
def download_one_stock(ticker):
    clean_ticker = ticker.split('"')[-2] if '"' in ticker else ticker
    clean_ticker = clean_ticker.strip()
    if clean_ticker.isdigit() and len(clean_ticker) <= 4: clean_ticker += ".TW"
    try:
        df = yf.download(clean_ticker, period="6mo", interval="1d", progress=False, auto_adjust=True)
        if not df.empty and len(df) >= 20:
            return clean_ticker, "ok", df
    except Exception as e:
        logger.warning(f"âš ï¸ {clean_ticker} ä¸‹è¼‰å¤±æ•—: {e}")
    return clean_ticker, "error", None

# --- 4. ä¸»åˆ†æå‡½å¼ ---
def analyze_and_update_sheets(gc, spreadsheet_name, stock_codes, stock_df):
    alerts = []
    taipei_now = datetime.now(TAIPEI_TZ)
    current_date_obj = taipei_now.date()
    
    # èª¿è©¦ï¼šé¡¯ç¤ºç•¶å‰æ—¥æœŸ
    logger.info(f"ğŸ“… ç•¶å‰å°åŒ—æ—¥æœŸ: {current_date_obj.strftime('%Y-%m-%d')}")

    try:
        sh = gc.open(spreadsheet_name)
        ws = sh.worksheet("å·¥ä½œè¡¨1")
        all_rows = ws.get_all_values()
        
        # ç²å–è¡¨é ­ï¼ˆç¬¬ä¸€è¡Œï¼‰
        headers = all_rows[0]
        
        # å»ºç«‹ä¸­æ–‡æ¬„ä½åç¨±åˆ°ç´¢å¼•çš„æ˜ å°„
        header_to_index = {}
        for idx, header in enumerate(headers):
            header_to_index[header.strip()] = idx
            logger.debug(f"è¡¨é ­ç´¢å¼• {idx}: {header.strip()}")
        
        # èª¿è©¦ï¼šé¡¯ç¤ºé‡è¦çš„æ¬„ä½ç´¢å¼•
        important_fields = ['KD_é€šçŸ¥é–‹é—œ', 'MACD_é€šçŸ¥é–‹é—œ', 'KD_å»é‡æ—¥æœŸ', 'MACD_å»é‡æ—¥æœŸ']
        for field in important_fields:
            if field in header_to_index:
                logger.info(f"âœ… æ‰¾åˆ°æ¬„ä½: {field} -> ç´¢å¼• {header_to_index[field]}")
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ¬„ä½: {field}")

        # å»ºç«‹è‚¡ç¥¨ä»£ç¢¼åˆ°è¡Œç´¢å¼•çš„æ˜ å°„
        code_to_row = {}
        for idx, row in enumerate(all_rows[1:], start=2):
            if not row or not row[0]: continue
            code = row[0].split('"')[-2] if '"' in row[0] else row[0]
            code_to_row[code.strip()] = idx

        successful_data = {}
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {executor.submit(download_one_stock, c): c for c in stock_codes}
            for f in as_completed(futures):
                ticker, status, data = f.result()
                if status == "ok": successful_data[ticker] = data

        update_cells_raw = []
        for code, df in successful_data.items():
            row_idx = code_to_row.get(code)
            if not row_idx: continue

            try:
                # --- æ ¸å¿ƒå¼·åŒ–ï¼šè™•ç†å¤šç¶­åº¦æ•¸æ“šæå– ---
                def get_clean_values(col_name):
                    col_data = df[col_name]
                    # å¦‚æœè©²æ¬„ä½æœ‰å¤šå€‹ sub-columnï¼Œå–ç¬¬ä¸€æ¬„ (iloc[:, 0])
                    if len(col_data.shape) > 1:
                        return col_data.iloc[:, 0].values.flatten().astype(float)
                    return col_data.values.flatten().astype(float)

                c = get_clean_values('Close')
                h = get_clean_values('High')
                l = get_clean_values('Low')
                
                clean_index = df.index[-len(c):]
                series_low = pd.Series(l, index=clean_index)
                series_high = pd.Series(h, index=clean_index)
            except Exception as e:
                logger.error(f"âŒ {code} æ•¸æ“šæ·±åº¦æ¸…æ´—å¤±æ•—: {e}")
                continue

            # è®€å–èˆŠè³‡æ–™åˆ—ï¼ˆä½¿ç”¨ä¸­æ–‡æ¬„ä½åç¨±ï¼‰
            old_row = all_rows[row_idx - 1]
            
            # ä½¿ç”¨ä¸­æ–‡æ¬„ä½åç¨±è®€å–æ•¸æ“š
            row_data = {
                'KD_SWITCH': old_row[header_to_index.get('KD_é€šçŸ¥é–‹é—œ', 10)] if len(old_row) > 10 else 'ON',
                'MACD_SWITCH': old_row[header_to_index.get('MACD_é€šçŸ¥é–‹é—œ', 13)] if len(old_row) > 13 else 'ON',
                'MA5_MA10_SWITCH': old_row[header_to_index.get('MA5/10_é€šçŸ¥é–‹é—œ', 16)] if len(old_row) > 16 else 'ON',
                'MA5_MA20_SWITCH': old_row[header_to_index.get('MA5/20_é€šçŸ¥é–‹é—œ', 19)] if len(old_row) > 19 else 'ON',
                'MA10_MA20_SWITCH': old_row[header_to_index.get('MA10/20_é€šçŸ¥é–‹é—œ', 22)] if len(old_row) > 22 else 'ON',
                'BIAS_SWITCH': old_row[header_to_index.get('ä¹–é›¢ç‡_é€šçŸ¥é–‹é—œ', 25)] if len(old_row) > 25 else 'ON',
                
                'KD_ALERT_DATE': old_row[header_to_index.get('KD_å»é‡æ—¥æœŸ', 11)] if len(old_row) > 11 else '',
                'MACD_ALERT_DATE': old_row[header_to_index.get('MACD_å»é‡æ—¥æœŸ', 14)] if len(old_row) > 14 else '',
                'MA5_MA10_ALERT_DATE': old_row[header_to_index.get('MA5/10_å»é‡æ—¥æœŸ', 17)] if len(old_row) > 17 else '',
                'MA5_MA20_ALERT_DATE': old_row[header_to_index.get('MA5/20_å»é‡æ—¥æœŸ', 20)] if len(old_row) > 20 else '',
                'MA10_MA20_ALERT_DATE': old_row[header_to_index.get('MA10/20_å»é‡æ—¥æœŸ', 23)] if len(old_row) > 23 else '',
                'BIAS_ALERT_DATE': old_row[header_to_index.get('ä¹–é›¢ç‡_å»é‡æ—¥æœŸ', 26)] if len(old_row) > 26 else '',
                
                'LOW_DAYS': old_row[header_to_index.get('ä½é»é–“éš”å¤©æ•¸', 5)] if len(old_row) > 5 else '999',
                'HIGH_DAYS': old_row[header_to_index.get('æœˆé«˜é»é–“éš”å¤©æ•¸', 6)] if len(old_row) > 6 else '999',
                'MA_TANGLE': old_row[header_to_index.get('å‡ç·šç³¾çºç‹€æ…‹', 7)] if len(old_row) > 7 else 'ä¸æ˜',
                'SLOPE_DESC': old_row[header_to_index.get('è¶¨å‹¢æ–œç‡æè¿°', 8)] if len(old_row) > 8 else 'ä¸æ˜',
                'BIAS_Val': old_row[header_to_index.get('10æ—¥ä¹–é›¢ç‡ (%)', 4)] if len(old_row) > 4 else '0.00%',
                'MA5_SLOPE': old_row[header_to_index.get('MA5 æ–œç‡æ•¸å€¼', 27)] if len(old_row) > 27 else 'N/A',
                'MA10_SLOPE': old_row[header_to_index.get('MA10 æ–œç‡æ•¸å€¼', 28)] if len(old_row) > 28 else 'N/A',
                'MA20_SLOPE': old_row[header_to_index.get('MA20 æ–œç‡æ•¸å€¼', 29)] if len(old_row) > 29 else 'N/A',
            }
            
            # æ·»åŠ èª¿è©¦æ—¥èªŒ
            logger.info(f"ğŸ“Š {code} - KDé–‹é—œ: {row_data['KD_SWITCH']}, KDä¸Šæ¬¡æ—¥æœŸ: '{row_data['KD_ALERT_DATE']}'")
            logger.info(f"ğŸ“Š {code} - MACDé–‹é—œ: {row_data['MACD_SWITCH']}, MACDä¸Šæ¬¡æ—¥æœŸ: '{row_data['MACD_ALERT_DATE']}'")

            # æŒ‡æ¨™è¨ˆç®—
            ma5, ma10, ma20 = sma(c, 5), sma(c, 10), sma(c, 20)
            slowk = sma(stoch(h, l, c), 3)
            slowd = sma(slowk, 3)
            macd_l, sig_l, _ = macd(c)

            # è¨Šè™Ÿ
            kd_sig, is_kd = ta_helpers.check_cross_signal(slowk[-1], slowd[-1], slowk[-2], slowd[-2], "KD")
            macd_sig, is_macd = ta_helpers.check_cross_signal(macd_l[-1], sig_l[-1], macd_l[-2], sig_l[-2], "MACD")

            # æ–œç‡èˆ‡è¼”åŠ©æ•¸å€¼
            s5, s10, s20 = round(ta_helpers.calculate_slope(ma5), 4), round(ta_helpers.calculate_slope(ma10), 4), round(ta_helpers.calculate_slope(ma20), 4)
            tangle = ta_helpers.check_ma_tangle(ma5, ma10, ma20)
            slope_desc = ta_helpers.get_slope_description(s5, s10, s20)
            bias = f"{round(((c[-1] / ma20[-1]) - 1) * 100, 2)}%" if not np.isnan(ma20[-1]) else "N/A"

            row_data.update({
                'MA_TANGLE': tangle, 'SLOPE_DESC': slope_desc, 'BIAS_Val': bias,
                'MA5_SLOPE': str(s5), 'MA10_SLOPE': str(s10), 'MA20_SLOPE': str(s20),
                'LOW_DAYS': str(ta_helpers.find_extreme_time_diff(series_low, float(l[-1]), 'LOW')),
                'HIGH_DAYS': str(ta_helpers.find_extreme_time_diff(series_high, float(h[-1]), 'HIGH'))
            })

            provider = old_row[header_to_index.get('æä¾›è€…', 2)] if len(old_row) > 2 else ""
            link = ta_helpers.get_static_link(code, provider)

            # ç”Ÿæˆè­¦å ±
            ta_helpers.process_single_signal('KD', is_kd, kd_sig, code, row_data, COLUMN_MAP, current_date_obj, alerts, [], update_cells_raw, row_idx, link)
            ta_helpers.process_single_signal('MACD', is_macd, macd_sig, code, row_data, COLUMN_MAP, current_date_obj, alerts, [], update_cells_raw, row_idx, link)

            # è¼”åŠ©æ•¸æ“šæ›´æ–°
            for k, v in [('latest_close', round(float(c[-1]), 2)), ('MA5_SLOPE', s5), ('MA10_SLOPE', s10), ('MA20_SLOPE', s20), ('BIAS_Val', bias), ('MA_TANGLE', tangle), ('SLOPE_DESC', slope_desc)]:
                update_cells_raw.append({'range': f"{COLUMN_MAP[k]}{row_idx}", 'values': [[v]]})

        # --- æ ¼å¼çµ±ä¸€è½‰æ› ---
        final_updates = []
        for item in update_cells_raw:
            if isinstance(item, dict):
                final_updates.append(item)
            elif isinstance(item, tuple):
                (col_letter, row_num), val = item
                final_updates.append({'range': f"{col_letter}{row_num}", 'values': [[val]]})

        if final_updates:
            ws.batch_update(final_updates, value_input_option='USER_ENTERED')
            logger.info(f"âœ… åˆ†æä»»å‹™åœ“æ»¿å®Œæˆï¼Œæ›´æ–°äº† {len(final_updates)} ç­†è³‡æ–™ã€‚")

    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±æ•—: {e}", exc_info=True)
    
    return alerts
